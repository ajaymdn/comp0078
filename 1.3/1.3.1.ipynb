{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(filepath = \"./Boston-filtered.csv\", testsize = 1/3):\n",
    "    data = pd.read_csv(filepath)\n",
    "\n",
    "    # Randomize the dataset and reset the index, randomstate is used to make the randomization reproducible\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Split the dataset into features and target\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    split_index = int(len(data) * (1 - testsize))\n",
    "\n",
    "    X_train = X[:split_index]\n",
    "    y_train = y[:split_index]\n",
    "\n",
    "    X_test = X[split_index:]\n",
    "    y_test = y[split_index:]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(xi, xj, sigma):\n",
    "    sq_dists = np.sum(xi**2, axis=1)[:, None] + np.sum(xj**2, axis=1)[None, :] - 2 * np.dot(xi, xj.T)\n",
    "    K = np.exp(-sq_dists / (2 * sigma**2))\n",
    "\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_ridge_regression(X_train, y_train, gamma, K):\n",
    "    ell = X_train.shape[0]\n",
    "    I = np.eye(ell)\n",
    "    alpha_star = np.linalg.inv(K + gamma * ell * I) @ y_train\n",
    "\n",
    "    return alpha_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gamma: 2.3283064365386963e-10 \n",
      "Best Sigma: 1024.0  \n",
      "Best Validation MSE: 11.464788148309989\n"
     ]
    }
   ],
   "source": [
    "gamma_values = [2**(-40 + i) for i in range(15)]\n",
    "sigma_values = [2**(7 + i * 0.5) for i in range(13)]\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_dataset()\n",
    "\n",
    "def cross_validation(X_train, y_train, gamma_values, sigma_values):\n",
    "    n = len(y_train)\n",
    "    fold_size = n // 5\n",
    "\n",
    "    best_gamma = None\n",
    "    best_sigma = None\n",
    "    best_mse = np.inf\n",
    "\n",
    "    mean_mse_vals = np.zeros((len(gamma_values), len(sigma_values)))\n",
    "\n",
    "    for gamma_index, gamma in enumerate(gamma_values):\n",
    "        for sigma_index, sigma in enumerate(sigma_values):\n",
    "            mse_val_errors = []\n",
    "            \n",
    "            for i in range(5):\n",
    "                val_start = i * fold_size\n",
    "                val_end = (i + 1) * fold_size if i < 4 else n\n",
    "\n",
    "                # Validation set\n",
    "                X_val = X_train[val_start:val_end]\n",
    "                y_val = y_train[val_start:val_end]\n",
    "\n",
    "                # Training set\n",
    "                X_train_fold = np.concatenate([X_train[:val_start], X_train[val_end:]], axis=0)\n",
    "                y_train_fold = np.concatenate([y_train[:val_start], y_train[val_end:]], axis=0)\n",
    "\n",
    "                K_train = gaussian_kernel(X_train_fold, X_train_fold, sigma)\n",
    "                K_val = gaussian_kernel(X_val, X_train_fold, sigma)\n",
    "\n",
    "                # \"Training model\"\n",
    "                alpha_star = kernel_ridge_regression(X_train_fold, y_train_fold, gamma, K_train)\n",
    "\n",
    "                y_val_pred = K_val @ alpha_star\n",
    "\n",
    "                mse_val_error = np.mean((y_val - y_val_pred) ** 2)\n",
    "                mse_val_errors.append(mse_val_error)\n",
    "\n",
    "            mean_mse_vals[gamma_index, sigma_index] = np.mean(mse_val_errors)\n",
    "\n",
    "            if np.mean(mse_val_errors) < best_mse:\n",
    "                best_mse = np.mean(mse_val_errors)\n",
    "                best_gamma = gamma\n",
    "                best_sigma = sigma\n",
    "\n",
    "    return best_gamma, best_sigma, best_mse, mean_mse_vals\n",
    "\n",
    "best_gamma, best_sigma,best_mse, mean_mse_vals = cross_validation(X_train, y_train, gamma_values, sigma_values)\n",
    "print(f\"Best Gamma: {best_gamma} \\nBest Sigma: {best_sigma}  \\nBest Validation MSE: {best_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using best gamma and sigma values\n",
      "Training MSE: 7.344273435848167\n",
      "Test MSE: 18.66496766746761\n"
     ]
    }
   ],
   "source": [
    "K_train_best = gaussian_kernel(X_train, X_train, best_sigma)\n",
    "K_test_best = gaussian_kernel(X_test, X_train, best_sigma)\n",
    "\n",
    "    # Step 2: Train the model with the best parameters (on the full training set)\n",
    "alpha_star_best = kernel_ridge_regression(X_train, y_train, best_gamma, K_train_best)\n",
    "\n",
    "    # Step 3: Predict for both training and test sets\n",
    "y_train_pred = K_train_best @ alpha_star_best\n",
    "y_test_pred = K_test_best @ alpha_star_best\n",
    "\n",
    "# Step 4: Compute MSE for both training and test sets\n",
    "train_mse = np.mean((y_train - y_train_pred) ** 2)\n",
    "test_mse = np.mean((y_test - y_test_pred) ** 2)\n",
    "\n",
    "print(f\"Using best gamma and sigma values\")\n",
    "print(f\"Training MSE: {train_mse}\")\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Error: 7.2584e+00 ± 1.4887e+00\n",
      "Mean Test Error: 1.3035e+01 ± 2.1731e+00\n"
     ]
    }
   ],
   "source": [
    "runs = 20\n",
    "\n",
    "MSE_train_errors = []\n",
    "MSE_test_errors = []\n",
    "\n",
    "for run in range(runs):\n",
    "    X_train, y_train, X_test, y_test = split_dataset()\n",
    "\n",
    "    best_gamma, best_sigma, best_mse, _ = cross_validation(X_train, y_train, gamma_values, sigma_values)\n",
    "\n",
    "    K_train_best = gaussian_kernel(X_train, X_train, best_sigma)\n",
    "    K_test_best = gaussian_kernel(X_test, X_train, best_sigma)\n",
    "\n",
    "    alpha_star_best = kernel_ridge_regression(X_train, y_train, best_gamma, K_train_best)\n",
    "\n",
    "    y_train_pred = K_train_best @ alpha_star_best\n",
    "    y_test_pred = K_test_best @ alpha_star_best\n",
    "\n",
    "    train_mse = np.mean((y_train - y_train_pred) ** 2)\n",
    "    test_mse = np.mean((y_test - y_test_pred) ** 2)\n",
    "\n",
    "    MSE_train_errors.append(train_mse)\n",
    "    MSE_test_errors.append(test_mse)\n",
    "\n",
    "train_errors = np.array(MSE_train_errors)\n",
    "test_errors = np.array(MSE_test_errors)\n",
    "\n",
    "mean_train_error = np.mean(train_errors)\n",
    "std_train_error = np.std(train_errors)\n",
    "mean_test_error = np.mean(test_errors)\n",
    "std_test_error = np.std(test_errors)\n",
    "\n",
    "print(f\"Mean Train Error: {mean_train_error:.4e} ± {std_train_error:.4e}\")\n",
    "print(f\"Mean Test Error: {mean_test_error:.4e} ± {std_test_error:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
